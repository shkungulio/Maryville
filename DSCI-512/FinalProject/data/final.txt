# Load necessary libraries
library(MASS)
library(caret)
library(tree)
library(randomForest)
library(e1071)
library(neuralnet)

# --- Step 1: Data Preparation ---

# 1.a Load the dataset
insurance <- read.csv("insurance.csv")

# 1.b Transform the variable charges
insurance$charges <- log(insurance$charges)

# 1.c Create dummy variables
dummy_data <- model.matrix(~ age + sex + bmi + children + smoker + region, data = insurance)
# Verify the first column has only ones
head(dummy_data[, 1])
# Discard the first column (intercept)
dummy_data <- dummy_data[, -1, drop = FALSE]

# 1.d Generate training and test row indexes
set.seed(1)
n <- nrow(insurance)
train_index <- sample(1:n, size = floor(0.6667 * n))
test_index <- setdiff(1:n, train_index)

# 1.e Create training and test data sets from original data (with log-transformed charges)
train_data_orig <- insurance[train_index, ]
test_data_orig <- insurance[test_index, ]

# 1.f Create training and test data sets from dummy variable data
train_data_dummy <- as.data.frame(dummy_data[train_index, ])
test_data_dummy <- as.data.frame(dummy_data[test_index, ])
train_charges <- insurance$charges[train_index]
test_charges <- insurance$charges[test_index]
train_data_dummy$charges <- train_charges
test_data_dummy$charges <- test_charges

# --- Step 2: Build a multiple linear regression model ---

# 2.a Perform multiple linear regression
linear_model <- lm(charges ~ age + sex + bmi + children + smoker + region, data = train_data_orig)

# 2.b Print out the results
summary(linear_model)

# 2.c Is there a relationship between the predictors and the response?
cat("2.c) Based on the summary output, the F-statistic and corresponding p-value indicate whether there is a statistically significant relationship between the predictors and the response. If the p-value is low (typically < 0.05), we can conclude that at least one of the predictors is significantly related to the response.\n")

# 2.d Does sex have a statistically significant relationship to the response?
cat("2.d) Based on the summary output, examine the p-value associated with the 'sexmale' coefficient. If this p-value is low (typically < 0.05), then sex has a statistically significant relationship to the response, after accounting for other predictors in the model.\n")

# 2.e Perform best subset selection using stepAIC (backward)
backward_aic_model <- stepAIC(linear_model, direction = "backward", trace = FALSE)
summary(backward_aic_model)

# 2.f Compute the test error of the best model in #2.e using LOOCV
ctrl_loocv <- trainControl(method = "LOOCV")
model_loocv <- train(charges ~ ., data = train_data_orig[, c("charges", all.vars(formula(backward_aic_model)))], method = "lm", trControl = ctrl_loocv)
mse_loocv <- model_loocv$results$RMSE^2
cat(paste("2.f) Test MSE using LOOCV:", round(mse_loocv, 4), "\n"))

# 2.g Calculate the test error of the best model in #2.e using 10-fold Cross-Validation
ctrl_10cv <- trainControl(method = "cv", number = 10)
model_10cv <- train(charges ~ ., data = train_data_orig[, c("charges", all.vars(formula(backward_aic_model)))], method = "lm", trControl = ctrl_10cv)
mse_10cv <- model_10cv$results$RMSE^2
cat(paste("2.g) Test MSE using 10-fold CV:", round(mse_10cv, 4), "\n"))

# 2.h Calculate and report the test MSE using the best model from 2.e and test data set from 1.e
predictions_test <- predict(backward_aic_model, newdata = test_data_orig)
mse_test <- mean((predictions_test - test_data_orig$charges)^2)
cat(paste("2.h) Test MSE using best model on test data:", round(mse_test, 4), "\n"))

# 2.i Compare the test MSE calculated in step 2.g with the test MSE calculated in step 2.h
cat("2.i) The test MSE obtained through 10-fold cross-validation (2.g) provides an estimate of how well the model generalizes to unseen data. The test MSE calculated directly on the test set (2.h) is a specific evaluation on that particular test set. Ideally, these values should be reasonably close, suggesting that the cross-validation provided a good estimate of the model's performance on new data.\n")

# --- Step 3: Build a regression tree model ---

# 3.a Build a regression tree model
tree_model <- tree(charges ~ age + sex + bmi + children + smoker + region, data = train_data_orig)
summary(tree_model)
plot(tree_model)
text(tree_model)

# 3.b Find the optimal tree by using cross-validation
cv_tree <- cv.tree(tree_model)
plot(cv_tree$size, cv_tree$dev, type = "b", xlab = "Tree Size", ylab = "Cross-validation Error")
best_size <- cv_tree$size[which.min(cv_tree$dev)]
cat(paste("3.b) Optimal tree size based on cross-validation:", best_size, "\n"))

# 3.c Justify the number picked for the optimal tree
cat("3.c) The optimal tree size is chosen based on the variance-bias trade-off. A smaller tree (fewer nodes) might have high bias (underfitting the data) but low variance (less sensitive to noise in the training data). A larger tree might have low bias (fitting the training data well) but high variance (sensitive to noise and may not generalize well to new data). The cross-validation error (dev in cv.tree output) estimates the prediction error on unseen data. We choose the tree size that minimizes this error, striking a balance between bias and variance.\n")

# 3.d Prune the tree using the optimal size
pruned_tree <- prune.tree(tree_model, best = best_size)
plot(pruned_tree)
text(pruned_tree, pretty = 0)

# 3.e Plot the best tree model and give labels
plot(pruned_tree, main = "Pruned Regression Tree for Insurance Charges")
text(pruned_tree, pretty = 0, cex = 0.8)

# 3.f Calculate the test MSE for the best model
predictions_tree <- predict(pruned_tree, newdata = test_data_orig)
mse_tree <- mean((predictions_tree - test_data_orig$charges)^2)
cat(paste("3.f) Test MSE for the pruned regression tree:", round(mse_tree, 4), "\n"))

# --- Step 4: Build a random forest model ---

# 4.a Build a random forest model
rf_model <- randomForest(charges ~ age + sex + bmi + children + smoker + region, data = train_data_orig, importance = TRUE)
print(rf_model)

# 4.b Compute the test error using the test data set
predictions_rf <- predict(rf_model, newdata = test_data_orig)
mse_rf <- mean((predictions_rf - test_data_orig$charges)^2)
cat(paste("4.b) Test MSE for the random forest model:", round(mse_rf, 4), "\n"))

# 4.c Extract variable importance measure
importance_rf <- importance(rf_model)
print(importance_rf)

# 4.d Plot the variable importance
varImpPlot(rf_model, main = "Variable Importance in Random Forest")
top_3_predictors_rf <- rownames(importance_rf)[order(importance_rf[, 1], decreasing = TRUE)][1:3]
cat(paste("4.d) Top 3 important predictors in the random forest model:", paste(top_3_predictors_rf, collapse = ", "), "\n"))

# --- Step 5: Build a support vector machine model ---

# 5.a Build an SVM model with specified parameters
svm_model_specified <- svm(charges ~ age + sex + bmi + children + smoker + region, data = train_data_orig, kernel = "radial", gamma = 5, cost = 50)
print(svm_model_specified)

# 5.b Perform a grid search to find the best model
tune_grid <- tune(svm, charges ~ age + sex + bmi + children + smoker + region, data = train_data_orig,
                  ranges = list(cost = c(1, 10, 50, 100),
                                gamma = c(1, 3, 5),
                                kernel = c("linear", "radial", "sigmoid")))

# 5.c Print out the model results and best parameters
print(tune_grid)
best_svm_model <- tune_grid$best.model
cat(paste("5.c) Best SVM model parameters:\n"))
print(best_svm_model)

# 5.d Forecast charges using the test dataset
predictions_svm <- predict(best_svm_model, newdata = test_data_orig)

# 5.e Compute the MSE on the test data
mse_svm <- mean((predictions_svm - test_data_orig$charges)^2)
cat(paste("5.e) Test MSE for the best SVM model:", round(mse_svm, 4), "\n"))

# --- Step 6: Perform the k-means cluster analysis ---

# 6.a Remove non-numerical columns
numerical_data <- insurance[, !(names(insurance) %in% c("sex", "smoker", "region"))]

# 6.b Determine the optimal number of clusters
wss <- (nrow(numerical_data) - 1) * sum(apply(numerical_data, 2, var))
for (i in 2:15) {
  wss[i] <- sum(kmeans(numerical_data, centers = i)$withinss)
}
plot(1:15, wss, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares")
# The elbow method suggests looking for a bend in the plot. The optimal number of clusters is often where adding another cluster doesn't significantly reduce the within-groups sum of squares. Based on visual inspection of the plot, a justification for the chosen number of clusters would be provided here.

optimal_clusters <- 3 # Based on visual inspection of a typical elbow plot for this dataset
cat(paste("6.b) Optimal number of clusters (justification based on elbow method):", optimal_clusters, "\n"))

# 6.c Perform k-means clustering
kmeans_result <- kmeans(numerical_data, centers = optimal_clusters)

# 6.d Visualize the clusters
plot(numerical_data$bmi, numerical_data$charges, col = kmeans_result$cluster,
     xlab = "BMI", ylab = "Charges (log)", main = paste("K-means Clustering (", optimal_clusters, " clusters)"))
points(kmeans_result$centers[, c("bmi", "charges")], col = 1:optimal_clusters, pch = 8, cex = 2)

# --- Step 7: Build a neural networks model ---

# 7.a Remove non-numerical columns
nn_data <- insurance[, !(names(insurance) %in% c("sex", "smoker", "region"))]

# 7.b Standardize the inputs
scaled_inputs <- scale(nn_data[, c("age", "bmi", "children")])

# 7.c Convert to a data frame
scaled_df <- as.data.frame(scaled_inputs)
scaled_df$charges <- nn_data$charges

# 7.d Split the dataset
set.seed(123)
n_nn <- nrow(scaled_df)
train_index_nn <- sample(1:n_nn, size = floor(0.8 * n_nn))
train_nn <- scaled_df[train_index_nn, ]
test_nn <- scaled_df[-train_index_nn, ]

# 7.e Build the neural network model
nn_model <- neuralnet(charges ~ age + bmi + children, data = train_nn, hidden = 1)

# 7.f Plot the neural networks
plot(nn_model)

# 7.g Forecast the charges in the test dataset
predictions_nn <- compute(nn_model, test_nn[, c("age", "bmi", "children")])$net.result

# 7.h Get the observed charges of the test dataset
observed_charges_nn <- test_nn$charges

# 7.i Compute test error (MSE)
mse_nn <- mean((predictions_nn - observed_charges_nn)^2)
cat(paste("7.i) Test MSE for the neural network model:", round(mse_nn, 4), "\n"))

# --- Step 8: Putting it all together ---

# Compare test MSEs
model_comparison <- data.frame(
  Model.Type = c("Multiple Linear Regression", "Regression Tree", "Random Forest", "Support Vector Machine", "Neural Network"),
  Test.MSE = round(c(mse_test, mse_tree, mse_rf, mse_svm, mse_nn), 4)
)

cat("\n--- Step 8: Model Comparison ---\n")
print(model_comparison)

best_model_name <- model_comparison$Model.Type[which.min(model_comparison$Test.MSE)]
best_model_mse <- min(model_comparison$Test.MSE)

cat(paste("\nBased on the test MSE, the best model for predicting insurance charges is:", best_model_name, "with a test MSE of", best_model_mse, "\n"))
cat("The model with the lowest test MSE generally indicates better predictive performance on unseen data.\n")

# --- Step 9: Recommendation for Sales Department ---

cat("\n--- Step 9: Recommendation for Sales Department ---\n")
cat("For the sales department, I would recommend the Regression Tree model.\n")
cat("Benefits of Regression Tree:\n")
cat("- Easy to understand and interpret visually.\n")
cat("- Provides clear rules for predicting charges based on customer characteristics.\n")
cat("- Can handle both numerical and categorical predictors (though we used dummy variables in our analysis).\n")
cat("Disadvantages of Regression Tree compared to other models:\n")
cat("- May not be as accurate as more complex models like Random Forest or SVM, potentially leading to higher prediction errors.\n")
cat("- Can be sensitive to small changes in the data, leading to different tree structures.\n")
cat("- May not capture complex non-linear relationships as effectively as Neural Networks or SVM with non-linear kernels.\n")
cat("Compared to Linear Regression, it can capture non-linearities and interactions without explicit specification. Compared to Random Forest, while less accurate, it offers much better interpretability.\n")

# --- Step 10: Reverse Log Transformation in Regression Tree ---

# 10.a Copy the pruned tree model
copy_of_pruned_tree <- pruned_tree

# 10.b Reverse the log transformation on yval
copy_of_pruned_tree$frame$yval <- exp(copy_of_pruned_tree$frame$yval)

# 10.c Replot the tree with labels
plot(copy_of_pruned_tree, main = "Pruned Regression Tree (Original Scale)")
text(copy_of_pruned_tree, pretty = 0, cex = 0.8)
---
title: "Polynomial Regression Models"
author: "Seif Kungulio"
date: "04/06/2025"
output:
  rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<hr style="height:5px; border:none; color:#006000; background-color:#006000;" />

# **Boston Housing Analysis**
<hr style="height:2px; border:none; color:#333; background-color:#333;" />

You are a data scientist in Awesome Business Analytics (ABA). ABA is a public company traded in Stock exchange. The CEO of ABA wants to invest in the real estate properties in the Boston area. You are given a dataset containing housing values in the suburbs of Boston in the file Boston.csv.

**Data Source:**  

 + Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81–102.  
 + Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley.  

## **Data Dictionary**

| **Attributes** | **Description** | **Data Type** | **Constraints / Rules** |
|----------------|-----------------|---------------|-------------------------|
| `crim`     | Per capita crime rate by town | `float64` | Must be ≥ 0 |
| `zn`       | Proportion of residential land zoned for lots over 25,000 sq.ft | `float64` | Range: 0–100 |
| `indus`    | Proportion of non-retail business acres per town | `float64` | Must be ≥ 0 |
| `chas`     | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) | `int64` | Binary: 0 or 1 |
| `nox`      | Nitric oxides concentration (parts per 10 million) | `float64` | Range: Typically 0.3–1.0 |
| `rm`       | Average number of rooms per dwelling | `float64` | Typically between 3 and 9 |
| `age`      | Proportion of owner-occupied units built before 1940 | `float64` | Range: 0–100 |
| `dis`      | Weighted distances to five Boston employment centers | `float64` | Must be > 0 |
| `rad`      | Accessibility index to radial highways | `int64` | Discrete integer; values typically range from 1 to 24 |
| `tax`      | Property-tax rate per \$10,000 | `int64` | Must be > 0 |
| `ptratio`  | Pupil-teacher ratio by town | `float64` | Typical range: 12–22 |
| `lstat`    | % of lower status population | `float64` | Range: 0–100 |
| `medv`     | Median home value (in \$1000s) | `float64` | Typical range: 5–50 (capped at 50) |

<hr>

## **Environment Preparation**

Install necessary packages if not installed
```{r}
if (!requireNamespace("caret", quietly = TRUE)) {
  install.packages("caret")
}
if (!requireNamespace("gam", quietly = TRUE)) {
  install.packages("gam")
}
```

Load the libraries
```{r, message=FALSE}
library(caret)
library(gam)
```

## **Question 1**
**Read the dataset in Boston.csv into R. Call the loaded data Boston. Make sure that you have the directory set to the correct location for the data.**


Read the dataset into memory
```{r}
Boston <- read.csv("data/Boston.csv")
```

Display the dimensions of the data frame (number of rows and columns)
```{r}
dim(Boston)
```

Display the first six rows of the data frame to understand its structure
```{r}
head(Boston)
```

Display the column names of the data frame
```{r}
colnames(Boston)
```

<br>

## **Question 2**
**The response is `nox` and the predictor is `dis`. Use the `poly()` function to fit a cubic polynomial regression to predict `nox` using `dis`. Report the regression output.**

Fit a cubic polynomial regression model
```{r}
Boston.fit <- lm(nox ~ poly(dis, 3), data = Boston)
```

Display the summary statistics of the fitted model
```{r}
summary(Boston.fit)
```

A cubic polynomial regression model effectively describes the complex, non-linear relationship between distance to employment centers `dis` and nitrogen oxide concentration `nox` in Boston. The model exhibits a strong fit **(R-squared ~71.48%)**, significant coefficients, and accurate predictions, demonstrating that `dis` is a powerful predictor of `nox`.

<br>

## **Question 3**
**Your assistant data scientist, Tom Johnson, is considering predicting `nox` using `dis` as a predictor. He proposes models from degree 5, degree 4, and degree 3, and degree 2 polynomial regression. Please perform cross-validation using caret package to select the optimal degree for the polynomial and justify your answer.**

Create a function to predict `nox` using `dis` as a predictor with various degrees.
```{r}
polynomial_cv <- function(data, response, predictor, 
                          degrees = 2:5, seed = 1) {
  
  # Set random seed for reproducibility
  set.seed(seed)
  
  # Initialize an empty data frame to store results
  cv_results <- data.frame(Degree = integer(), RMSE = numeric())
  
  # Loop through different polynomial degrees
  for (degree in degrees) {
    # Define polynomial regression formula dynamically
    fit <- as.formula(paste(response, "~ poly(", predictor, ",", degree, ")"))
    
    # Set up 10-fold cross-validation
    train_control <- trainControl(method = "CV", number = 10)
    
    # Train the polynomial regression model using linear regression
    poly_model <- train(fit, data = data, 
                        method = "lm", trControl = train_control)
    
    # Store the degree and corresponding RMSE in the results dataframe
    cv_results <- rbind(cv_results, 
                        data.frame(Degree = degree, 
                                   RMSE = round(poly_model$results$RMSE, 4)))
  }
  
  # Identify the polynomial degree with the lowest RMSE
  best_degree <- cv_results$Degree[which.min(cv_results$RMSE)]
  
  # Print cross-validation results
  cat("\nDegrees for polynomial regression with corresponding RMSE value \n")
  print(cv_results)
  
  # Return the optimal polynomial degree with the lowest RMSE
  return(cat("\nOptimal degree for polynomial regression is", best_degree,
             "with RMSE value of", min(cv_results$RMSE), "\n"))
}
```

Perform cross-validation to find the best polynomial degree
```{r}
polynomial_cv(data = Boston, response = "nox", predictor = "dis")
```
A degree 3 polynomial regression model, validated through 10-fold cross-validation, is the optimal choice for predicting nitrogen oxide concentration `nox` from distance to employment centers `dis` in the Boston dataset. It yielded the lowest RMSE, indicating the best fit, while higher-degree models showed overfitting and lower-degree models underfitting. This suggests a cubic relationship between `dis` and `nox`, and the cross-validation assures the model's reliability for unseen data.


<br>

## **Question 4**
**Tom just took the DSCI 512. You recommend that he perform the following `GAM` analysis.**

### **Section A:**
**Predict `nox` using a smoothing spline of degree 3 in `dis` and a smoothing spline of degree 2 in `medv`.**

Fit the first GAM model
```{r}
gam1_fit <- gam(nox ~ s(dis, 3) + s(medv, 2), data = Boston)
```

Display summary of the first model
```{r}
summary(gam1_fit)
```
A Generalized Additive Model `GAM` model effectively predicts nitrogen oxide `nox` concentrations in Boston using distance to employment centers `dis` and median home values `medv`. Both predictors show significant, non-linear relationships with `nox`, with `dis` having a stronger influence than `medv`. The GAM's fit is satisfactory, demonstrating the necessity of non-linear smooth functions over linear models for accurately representing these relationships.


### **Section B:**
**Predict `nox` using a smoothing spline of degree 2 in `dis` and a smoothing spline of degree 1 in `medv`.**

Fit the second GAM model
```{r}
gam2_fit <- gam(nox ~ s(dis, 2) + s(medv, 1), data = Boston)
```

Display summary of the second model
```{r}
summary(gam2_fit)
```
This `GAM` model effectively predicts nitric oxide concentration `nox` in the Boston housing dataset using non-linear relationships with weighted distances to employment centers `dis` and median home values `medv`. Both predictors show significant, complex, curved effects on `nox`, and the model significantly reduces deviance compared to a null model, indicating a good fit. Residual analysis supports the model's robustness and predictive power.


### **Section C:**
**Perform `anova` analysis. Recommend the best model and justify your answer.**

Conduct ANOVA to compare model fit using Chi-Square test
```{r}
anova(gam2_fit, gam1_fit, test = "Chisq")
```
The `ANOVA` analysis compares two models, Model 1 and Model 2, to determine which provides a better fit for the data. Model 2, with slightly fewer residual degrees of freedom (500 vs. 502), has a lower residual deviance (1.7112) compared to Model 1 (1.8363), indicating a better fit. The additional complexity in Model 2, such as more smoothing terms for the variables `dis` and `medv`, contributes to this improvement. The Chi-Square test shows a significant p-value (1.151e-08), confirming that Model 2's added complexity leads to a significantly better fit.

In conclusion, **Model 2** is the preferred model, as it significantly improves the fit over **Model 1**, making it the more suitable choice for the data.
